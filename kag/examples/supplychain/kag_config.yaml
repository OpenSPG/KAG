#------------project configuration start----------------#
openie_llm: &openie_llm
  type: maas
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  api_key: key
  model: qwen2.5-7b-instruct-1m
  enable_check: false

chat_llm: &chat_llm
  type: maas
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  api_key: key
  model: qwen2.5-72b-instruct
  enable_check: false

vectorize_model: &vectorize_model
  api_key: key
  base_url: https://api.siliconflow.cn/v1
  model: BAAI/bge-m3
  type: openai
  vector_dimensions: 1024
  enable_check: false
vectorizer: *vectorize_model

log:
  level: INFO

project:
  biz_scene: default
  host_addr: http://127.0.0.1:8887
  id: '12'
  language: zh
  namespace: SupplyChain
  checkpoint_path: ./extract-runner-ckpt
#------------project configuration end----------------#

#------------kag-solver configuration start----------------#
search_api: &search_api
  type: openspg_search_api #kag.solver.tools.search_api.impl.openspg_search_api.OpenSPGSearchAPI

graph_api: &graph_api
  type: openspg_graph_api #kag.solver.tools.graph_api.impl.openspg_graph_api.OpenSPGGraphApi

chain_vectorizer:
  type: batch
  vectorize_model: *vectorize_model

kg_cs: &kg_cs
  type: kg_cs_open_spg
  path_select:
    type: exact_one_hop_select
    graph_api: *graph_api
    search_api: *search_api
  entity_linking:
    type: entity_linking
    graph_api: *graph_api
    search_api: *search_api
    recognition_threshold: 0.9
    exclude_types:
      - Chunk

kg_fr: &kg_fr
  type: kg_fr_open_spg
  top_k: 20
  graph_api: *graph_api
  search_api: *search_api
  vectorize_model: *vectorize_model
  path_select:
    type: fuzzy_one_hop_select
    llm_client: *openie_llm
    graph_api: *graph_api
    search_api: *search_api
  ppr_chunk_retriever_tool:
    type: ppr_chunk_retriever
    llm_client: *chat_llm
    graph_api: *graph_api
    search_api: *search_api
  entity_linking:
    type: entity_linking
    graph_api: *graph_api
    search_api: *search_api
    recognition_threshold: 0.8
    exclude_types:
      - Chunk

rc: &rc
  type: rc_open_spg
  vector_chunk_retriever:
    type: vector_chunk_retriever_legacy
    vectorize_model: *vectorize_model
    search_api: *search_api
  graph_api: *graph_api
  search_api: *search_api
  vectorize_model: *vectorize_model
  top_k: 20

kag_merger:
  type: kg_merger
  top_k: 20
  llm_module: *chat_llm
  summary_prompt:
    type: default_thought_then_answer
  vectorize_model: *vectorize_model
  graph_api: *graph_api
  search_api: *search_api

kag_hybrid_executor: &kag_hybrid_executor_conf
  type: kag_hybrid_retrieval_executor
  retrievers:
    - *kg_cs
    - *kg_fr
    - *rc
  merger:
    type: kag_merger
  enable_summary: true


kag_output_executor: &kag_output_executor_conf
  type: kag_output_executor

kag_deduce_executor: &kag_deduce_executor_conf
  type: kag_deduce_executor


py_code_based_math_executor: &py_code_based_math_executor_conf
  type: py_code_based_math_executor
  llm: *chat_llm

kag_solver_pipeline:
  type: kag_static_pipeline
  planner:
    type: lf_kag_static_planner
    llm: *chat_llm
    plan_prompt:
      type: supplychain_lf_plan
    rewrite_prompt:
      type: default_rewrite_sub_task_query
  executors:
    - *kag_hybrid_executor_conf
    - *py_code_based_math_executor_conf
    - *kag_deduce_executor_conf
    - *kag_output_executor_conf
  generator:
    type: llm_generator
    llm_client: *chat_llm
    generated_prompt:
      type: resp_supplychain
    enable_ref: true
#------------kag-solver configuration end----------------#

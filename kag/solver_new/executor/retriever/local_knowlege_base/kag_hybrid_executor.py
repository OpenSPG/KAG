from typing import List, Any

from kag.builder.prompt.utils import init_prompt_with_fallback
from kag.interface import ExecutorABC, LLMClient, ExecutorResponse
from kag.interface.solver.base_model import SPOEntity
from kag.solver.logic.core_modules.common.one_hop_graph import (
    KgGraph,
    EntityData,
)
from kag.solver.logic.core_modules.parser.logic_node_parser import GetSPONode
from kag.tools.algorithm_tool.chunk_retriever.ppr_chunk_retriever import (
    PprChunkRetriever,
)
from kag.tools.algorithm_tool.graph_retriever.entity_linking import EntityLinking
from kag.tools.algorithm_tool.graph_retriever.path_select.path_select import PathSelect


class SubRetrievedData:
    """Container for retrieved data from a single logical node processing step.

    Attributes:
        sub_question (str): Sub-question being processed
        summary (str): Summary generated by LLM
        chunks (List[str]): Retrieved text chunks
        spo (List[RelationData]): SPO relations retrieved from knowledge graph
    """

    def __init__(self):
        self.sub_question = ""  # Sub-question text
        self.summary = ""  # Generated summary
        self.chunks = []  # List of retrieved text chunks
        self.spo = []  # List of SPO relation data objects

    def __repr__(self) -> str:
        """Generate debug-friendly string representation"""
        return f"""sub question: {self.sub_question}
retrieved chunks: 
{self.chunks}

retrieved spo: 
{self.spo}

summary:
{self.summary}
"""


class KAGRetrievedResponse(ExecutorResponse):
    """Response object containing retrieved data from knowledge graph processing.

    Attributes:
        sub_retrieved_set (List[SubRetrievedData]): List of processed sub-question results
        retrieved_task (str): Original task description
    """

    def __init__(self):
        super().__init__()
        self.sub_retrieved_set = []  # Collection of processed sub-question results
        self.retrieved_task = ""  # Original task description

    def to_string(self) -> str:
        """Convert response to human-readable string format

        Returns:
            str: Formatted string containing task description and sub-question results

        Note:
            Contains formatting error: "task: f{self.retrieved_task}"
            should be corrected to "task: {self.retrieved_task}"
        """
        return f"task: f{self.retrieved_task}" + "\n".join(
            [str(item) for item in self.sub_retrieved_set]
        )


@ExecutorABC.register("kag_hybrid_executor")
class KagHybridExecutor(ExecutorABC):
    """Hybrid knowledge graph retrieval executor combining multiple strategies.

    Combines entity linking, path selection, and text chunk retrieval using
    knowledge graph and LLM capabilities to answer complex queries.
    """

    def __init__(
        self,
        entity_linking: EntityLinking,
        path_select: PathSelect,
        ppr_chunk_retriever: PprChunkRetriever,
        llm_client: LLMClient,
    ):
        """Initialize hybrid retrieval executor with required components

        Args:
            entity_linking (EntityLinking): Entity linking tool
            path_select (PathSelect): Path selection strategy
            ppr_chunk_retriever (PprChunkRetriever): PageRank-based chunk retriever
            llm_client (LLMClient): Language model interface
        """
        super().__init__()
        self.entity_linking = entity_linking
        self.path_select = path_select
        self.ppr_chunk_retriever = ppr_chunk_retriever
        self.llm_client = llm_client

    @property
    def output_types(self):
        """Output type specification for executor responses"""
        return KAGRetrievedResponse

    def _trans_query_to_logic_form(self, query: str) -> List[GetSPONode]:
        """Convert user query to logical form (SPO nodes)

        Args:
            query (str): User input query text

        Returns:
            List[GetSPONode]: List of logical nodes representing SPO triples

        Note:
            Method is currently unimplemented and returns empty list
        """
        # TODO: Implement query parsing logic here
        return []

    def invoke(
        self, query: str, task: Any, context: dict, **kwargs
    ) -> KAGRetrievedResponse:
        """Execute hybrid knowledge graph retrieval process

        Args:
            query (str): User input question
            task: Task configuration object
            context (dict): Context information for retrieval
            **kwargs: Additional parameters

        Returns:
            KAGRetrievedResponse: Aggregated retrieval results

        Steps:
            1. Initialize response container
            2. Convert query to logical form
            3. Initialize knowledge graph container
            4. Process each logical node
            5. Retrieve text chunks
            6. Generate summaries
            7. Save intermediate results
            8. Store final results
        """
        # 1. Initialize response container

        kag_response = self._initialize_response(task)
        # TODO 在拆解的时候应该需要本任务依赖的任务，此处需要从context中获取，还需要改下代码
        # 2. Convert query to logical form
        logic_nodes = self._convert_to_logical_form(task.task_description, task)

        # 3. Initialize knowledge graph
        kg_graph = self._initialize_knowledge_graph()

        # 4-7 Process each logical node
        for logic_node in logic_nodes:
            # 4. Retrieve from kg
            self._retrieved_on_graph(kg_graph, logic_node)

            # 5. Retrieve text chunks
            chunks = self._retrieved_text_chunks(kg_graph, logic_node)

            # 6. Generate summary
            summary = self._generate_summary(logic_node, chunks, kg_graph)

            # 7. Save results
            self._save_step_result(kag_response, logic_node, chunks, summary, kg_graph)

        # 8. Final storage
        # TODO 此处存储生成的响应值，在后续任务重需要序列化输入给大模型进行重思考或者生成代码
        self._store_results(task, kag_response)
        return kag_response

    def _initialize_response(self, task) -> KAGRetrievedResponse:
        """Create and initialize response container

        Args:
            task: Task configuration object containing description

        Returns:
            KAGRetrievedResponse: Initialized response object
        """
        response = KAGRetrievedResponse()
        response.retrieved_task = str(task.task_description)
        return response

    def _convert_to_logical_form(self, query: str, task) -> List[GetSPONode]:
        """Convert task description to logical nodes

        Args:
            query (str): User input query
            task: Task configuration object

        Returns:
            List[GetSPONode]: Logical nodes derived from task description
        """
        return self._trans_query_to_logic_form(task.task_description)

    def _initialize_knowledge_graph(self) -> KgGraph:
        """Create new knowledge graph container for processing"""
        return KgGraph()

    def _retrieved_on_graph(self, kg_graph: KgGraph, logic_node: GetSPONode):
        """Process single logical node's entities and relations

        Args:
            kg_graph (KgGraph): Current knowledge graph instance
            logic_node (GetSPONode): Logical node to process
        """
        self._store_lf_node_structure(kg_graph, logic_node)
        start_entities = self._find_start_entities(kg_graph, logic_node)
        if not start_entities:
            return  # Skip if no valid start entities found

        self._retrieve_relations(kg_graph, logic_node, start_entities)

    def _store_lf_node_structure(self, kg_graph: KgGraph, logic_node: GetSPONode):
        """Store logical node structure in knowledge graph

        Args:
            kg_graph (KgGraph): Knowledge graph instance
            logic_node (GetSPONode): Current logical node
        """
        predicate = logic_node.p.alias_name
        kg_graph.query_graph[predicate] = {
            "s": logic_node.s.alias_name,
            "p": predicate,
            "o": logic_node.o.alias_name,
        }

    def _find_start_entities(
        self, kg_graph: KgGraph, logic_node: GetSPONode
    ) -> List[EntityData]:
        """Find starting entities for path selection

        Args:
            kg_graph (KgGraph): Current knowledge graph
            logic_node (GetSPONode): Current logical node

        Returns:
            List[EntityData]: List of found entities or None
        """
        heads = [logic_node.s, logic_node.o]
        for head in heads:
            # Try existing entities in knowledge graph
            entities = kg_graph.get_entity_by_alias(head.alias_name)
            if entities:
                kg_graph.entity_map[head.alias_name] = entities
                return entities
            if not isinstance(head, SPOEntity):
                continue
            # Perform entity linking if possible
            if logic_node.s.entity_name:
                entities = self.entity_linking.invoke(logic_node.sub_query, head)
                if entities:
                    kg_graph.entity_map[head.alias_name] = entities
                    return entities

        return None

    def _retrieve_relations(
        self,
        kg_graph: KgGraph,
        logic_node: GetSPONode,
        start_entities: List[EntityData],
    ):
        """Retrieve relations based on start entities

        Args:
            kg_graph (KgGraph): Knowledge graph instance
            logic_node (GetSPONode): Current logical node
            start_entities (List[EntityData]): Starting entities
        """
        selected_relations = []
        for entity in start_entities:
            new_relations = self.path_select.invoke(
                logic_node.sub_query, logic_node, entity
            )
            if new_relations:
                selected_relations.extend(new_relations)

        predicate = logic_node.p.alias_name
        kg_graph.edge_map[predicate] = selected_relations

    def _retrieved_text_chunks(
        self, kg_graph: KgGraph, logic_node: GetSPONode
    ) -> List[str]:
        """Retrieve text chunks using PPR chunk retriever

        Args:
            kg_graph (KgGraph): Current knowledge graph
            logic_node (GetSPONode): Current logical node

        Returns:
            List[str]: Retrieved text chunks
        """
        all_entities = kg_graph.get_all_entity()
        return self.ppr_chunk_retriever.invoke(
            query=logic_node.sub_query, start_entities=all_entities, top_k=5
        )

    def _generate_summary(
        self, logic_node: GetSPONode, chunks: List[str], kg_graph: KgGraph
    ):
        """Generate summary using LLM

        Args:
            logic_node (GetSPONode): Current logical node
            chunks (List[str]): Retrieved text chunks
            kg_graph (KgGraph): Knowledge graph data

        Returns:
            str: Generated summary text
        """
        relations = kg_graph.edge_map.get(logic_node.p.alias_name, [])
        return self.llm_client.invoke(
            {"query": logic_node.sub_query, "chunks": chunks, "spos": relations},
            init_prompt_with_fallback("sub_question_summary", "default"),
        )

    def _save_step_result(
        self,
        response: KAGRetrievedResponse,
        logic_node: GetSPONode,
        chunks: List[str],
        summary: str,
        kg_graph: KgGraph,
    ):
        """Save intermediate processing results

        Args:
            response (KAGRetrievedResponse): Aggregation container
            logic_node (GetSPONode): Current logical node
            chunks (List[str]): Retrieved text chunks
            summary (str): Generated summary
            kg_graph (KgGraph): Knowledge graph data
        """
        result = SubRetrievedData()
        result.sub_question = logic_node.sub_query
        result.summary = summary
        result.chunks = chunks
        result.spo = kg_graph.edge_map.get(logic_node.p.alias_name, [])
        response.sub_retrieved_set.append(result)

    def _store_results(self, task, response: KAGRetrievedResponse):
        """Store final results in task context

        Args:
            task: Task configuration object
            response (KAGRetrievedResponse): Processed results
        """
        task.add_memory("response", response)
        task.add_result(response)

    def schema(self) -> dict:
        """Function schema definition for OpenAI Function Calling

        Returns:
            dict: Schema definition in OpenAI Function format
        """
        return {
            "name": "kag_retriever_executor",
            "description": "Retrieve knowledge graph paths based on query and context to answer questions",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "User input question or query text",
                    }
                },
                "required": ["query"],
            },
        }

from typing import List, Any

from kag.builder.prompt.utils import init_prompt_with_fallback
from kag.common.conf import KAG_PROJECT_CONF
from kag.interface import ExecutorABC, LLMClient, ExecutorResponse, PromptABC
from kag.interface.solver.base_model import SPOEntity, SPORelation, LogicNode
from kag.solver.logic.core_modules.common.one_hop_graph import (
    KgGraph,
    EntityData,
)
from kag.solver.logic.core_modules.common.schema_utils import SchemaUtils
from kag.solver.logic.core_modules.config import LogicFormConfiguration
from kag.solver.logic.core_modules.parser.logic_node_parser import GetSPONode, ParseLogicForm
from kag.solver.logic.core_modules.parser.schema_std import SchemaRetrieval
from kag.tools.algorithm_tool.chunk_retriever.ppr_chunk_retriever import (
    PprChunkRetriever,
)
from kag.tools.algorithm_tool.graph_retriever.entity_linking import EntityLinking
from kag.tools.algorithm_tool.graph_retriever.path_select.path_select import PathSelect


class SubRetrievedData:
    """Container for retrieved data from a single logical node processing step.

    Attributes:
        sub_question (str): Sub-question being processed
        summary (str): Summary generated by LLM
        chunks (List[str]): Retrieved text chunks
        spo (List[RelationData]): SPO relations retrieved from knowledge graph
    """

    def __init__(self):
        self.sub_question = ""  # Sub-question text
        self.summary = ""  # Generated summary
        self.chunks = []  # List of retrieved text chunks
        self.spo = []  # List of SPO relation data objects

    def __repr__(self) -> str:
        """Generate debug-friendly string representation"""
        return f"""sub question: {self.sub_question}
retrieved chunks: 
{self.chunks}

retrieved spo: 
{self.spo}

summary:
{self.summary}
"""


class KAGRetrievedResponse(ExecutorResponse):
    """Response object containing retrieved data from knowledge graph processing.

    Attributes:
        sub_retrieved_set (List[SubRetrievedData]): List of processed sub-question results
        retrieved_task (str): Original task description
    """

    def __init__(self):
        super().__init__()
        self.sub_retrieved_set = []  # Collection of processed sub-question results
        self.retrieved_task = ""  # Original task description
    def __str__(self):
        return f"task: f{self.retrieved_task}" + "\n".join(
            [str(item) for item in self.sub_retrieved_set]
        )

    __repr__=__str__

    def to_string(self) -> str:
        """Convert response to human-readable string format

        Returns:
            str: Formatted string containing task description and sub-question results

        Note:
            Contains formatting error: "task: f{self.retrieved_task}"
            should be corrected to "task: {self.retrieved_task}"
        """
        return str(self)


@ExecutorABC.register("kag_hybrid_executor")
class KagHybridExecutor(ExecutorABC):
    """Hybrid knowledge graph retrieval executor combining multiple strategies.

    Combines entity linking, path selection, and text chunk retrieval using
    knowledge graph and LLM capabilities to answer complex queries.
    """

    def __init__(
        self,
        entity_linking: EntityLinking,
        path_select: PathSelect,
        ppr_chunk_retriever: PprChunkRetriever,
        llm_client: LLMClient,
        lf_trans_prompt: PromptABC = None
    ):
        """Initialize hybrid retrieval executor with required components

        Args:
            entity_linking (EntityLinking): Entity linking tool
            path_select (PathSelect): Path selection strategy
            ppr_chunk_retriever (PprChunkRetriever): PageRank-based chunk retriever
            llm_client (LLMClient): Language model interface
            lf_trans_prompt (PromptABC): prompt for logic form translator
        """
        super().__init__()
        self.entity_linking = entity_linking
        self.path_select = path_select
        self.ppr_chunk_retriever = ppr_chunk_retriever
        self.llm_client = llm_client
        self.lf_trans_prompt = lf_trans_prompt

        self.schema_helper: SchemaUtils = SchemaUtils(
            LogicFormConfiguration(
                {
                    "KAG_PROJECT_ID": KAG_PROJECT_CONF.project_id,
                    "KAG_PROJECT_HOST_ADDR": KAG_PROJECT_CONF.host_addr,
                }
            )
        )

        self.std_schema = SchemaRetrieval(
            vectorize_model=self.entity_linking.vectorize_model, llm_client=llm_client
        )

        self.logic_node_parser = ParseLogicForm(schema=self.schema_helper, schema_retrieval=self.std_schema)

    @property
    def output_types(self):
        """Output type specification for executor responses"""
        return KAGRetrievedResponse

    def _process_output_query(self, question, sub_query: str):
        if sub_query is None:
            return question
        if "output" == sub_query.lower():
            return f"output `{question}` answer:"
        return sub_query

    def _parse_lf(self, question, sub_querys, logic_forms) -> List[GetSPONode]:
        if sub_querys is None:
            sub_querys = []
        # process sub query
        sub_querys = [self._process_output_query(question, q) for q in sub_querys]
        if len(sub_querys) != len(logic_forms):
            raise RuntimeError(
                f"sub query not equal logic form num {len(sub_querys)} != {len(logic_forms)}"
            )
        return self.logic_node_parser.parse_logic_form_set(
            logic_forms, sub_querys, question
        )


    def _trans_query_to_logic_form(self, query: str, context: str) -> List[GetSPONode]:
        """Convert user query to logical form (SPO nodes)

        Args:
            query (str): User input query text
            context (str): Context for this question

        Returns:
            List[GetSPONode]: List of logical nodes representing SPO triples

        Note:
            Method is currently unimplemented and returns empty list
        """
        sub_queries, lf_nodes_str = self.llm_client.invoke(
            {"question": query, "context": context},
            self.lf_trans_prompt,
            with_json_parse=False,
            with_except=True,
        )
        return self._parse_lf(question=query, sub_querys=sub_queries, logic_forms=lf_nodes_str)

    def invoke(
        self, query: str, task: Any, context: dict, **kwargs
    ) -> KAGRetrievedResponse:
        """Execute hybrid knowledge graph retrieval process

        Args:
            query (str): User input question
            task: Task configuration object
            context (dict): Context information for retrieval
            **kwargs: Additional parameters

        Returns:
            KAGRetrievedResponse: Aggregated retrieval results

        Steps:
            1. Initialize response container
            2. Convert query to logical form
            3. Initialize knowledge graph container
            4. Process each logical node
            5. Retrieve text chunks
            6. Generate summaries
            7. Save intermediate results
            8. Store final results
        """
        # 1. Initialize response container
        kag_response = self._initialize_response(task)
        # 2. Convert query to logical form
        task_query = task.arguments['query']
        logic_nodes = self._convert_to_logical_form(task_query, task)

        # 3. Initialize knowledge graph
        kg_graph = self._initialize_knowledge_graph()

        # 4-7 Process each logical node
        for logic_node in logic_nodes:
            # 4. Retrieve from kg
            self._retrieved_on_graph(kg_graph, logic_node)

            # 5. Retrieve text chunks
            chunks = self._retrieved_text_chunks(kg_graph, logic_node)

            # 6. Generate summary
            summary = self._generate_summary(logic_node, chunks, kg_graph)

            # 7. Save results
            self._save_step_result(kag_response, logic_node, chunks, summary, kg_graph)

        # 8. Final storage
        self._store_results(task, kag_response)

    def _initialize_response(self, task) -> KAGRetrievedResponse:
        """Create and initialize response container

        Args:
            task: Task configuration object containing description

        Returns:
            KAGRetrievedResponse: Initialized response object
        """
        response = KAGRetrievedResponse()
        response.retrieved_task = str(task)
        return response

    def _convert_to_logical_form(self, query: str, task) -> List[GetSPONode]:
        """Convert task description to logical nodes

        Args:
            query (str): User input query
            task: Task configuration object

        Returns:
            List[GetSPONode]: Logical nodes derived from task description
        """
        # TODO 在拆解的时候应该需要本任务依赖的任务，此处需要从context中获取，还需要改下代码
        dep_tasks = task.parents
        context = []
        for dep_task in dep_tasks:
            if not dep_task.result:
                continue
            context.append(dep_task.result)
        return self._trans_query_to_logic_form(query, str(context))

    def _initialize_knowledge_graph(self) -> KgGraph:
        """Create new knowledge graph container for processing"""
        return KgGraph()

    def _retrieved_on_graph(self, kg_graph: KgGraph, logic_node: GetSPONode):
        """Process single logical node's entities and relations

        Args:
            kg_graph (KgGraph): Current knowledge graph instance
            logic_node (GetSPONode): Logical node to process
        """
        self._store_lf_node_structure(kg_graph, logic_node)
        head_entities = self._find_head_entities(kg_graph, logic_node)
        tail_entities = self._find_tail_entities(kg_graph, logic_node)
        if len(head_entities) == 0 or len(tail_entities) == 0:
            return
        self._retrieve_relations(kg_graph=kg_graph, logic_node=logic_node, head_entities=head_entities, tail_entities=tail_entities)

    def _store_lf_node_structure(self, kg_graph: KgGraph, logic_node: GetSPONode):
        """Store logical node structure in knowledge graph

        Args:
            kg_graph (KgGraph): Knowledge graph instance
            logic_node (GetSPONode): Current logical node
        """
        predicate = logic_node.p.alias_name
        kg_graph.query_graph[predicate] = {
            "s": logic_node.s.alias_name,
            "p": predicate,
            "o": logic_node.o.alias_name,
        }

    def _find_entities(self, kg_graph: KgGraph, symbol_entity: SPOEntity, query: str):
        # Try existing entities in knowledge graph
        entities = kg_graph.get_entity_by_alias(symbol_entity.alias_name)
        if entities:
            kg_graph.entity_map[symbol_entity.alias_name] = entities
            return entities
        # Perform entity linking if possible
        if symbol_entity.entity_name:
            entities = self.entity_linking.invoke(query, symbol_entity.get_mention_name(), symbol_entity.get_entity_first_type_or_un_std())
            if entities:
                kg_graph.entity_map[symbol_entity.alias_name] = entities
                return entities
        return []

    def _find_tail_entities(
        self, kg_graph: KgGraph, logic_node: GetSPONode
    ) -> List[EntityData]:
        """Find tails entities for path selection

        Args:
            kg_graph (KgGraph): Current knowledge graph
            logic_node (GetSPONode): Current logical node

        Returns:
            List[EntityData]: List of found entities or None
        """
        return self._find_entities(kg_graph, logic_node.o, logic_node.sub_query)
    def _find_head_entities(
        self, kg_graph: KgGraph, logic_node: GetSPONode
    ) -> List[EntityData]:
        """Find heads entities for path selection

        Args:
            kg_graph (KgGraph): Current knowledge graph
            logic_node (GetSPONode): Current logical node

        Returns:
            List[EntityData]: List of found entities or None
        """
        if isinstance(logic_node.s, SPOEntity):
            return self._find_entities(kg_graph, logic_node.s, logic_node.sub_query)
        return []


    def _retrieve_relations(
        self,
        kg_graph: KgGraph,
        logic_node: GetSPONode,
        head_entities: List[EntityData],
        tail_entities: List[EntityData]
    ):
        """Retrieve relations based on start entities

        Args:
            kg_graph (KgGraph): Knowledge graph instance
            logic_node (GetSPONode): Current logical node
            head_entities (List[EntityData]): Head entities
            tail_entities (List[EntityData]): Tail entities
        """
        selected_relations = self.path_select.invoke(
            query=logic_node.sub_query, spo=logic_node, heads=head_entities, tails=tail_entities
        )
        predicate = logic_node.p.alias_name
        kg_graph.edge_map[predicate] = selected_relations

    def _retrieved_text_chunks(
        self, kg_graph: KgGraph, logic_node: GetSPONode
    ) -> List[str]:
        """Retrieve text chunks using PPR chunk retriever

        Args:
            kg_graph (KgGraph): Current knowledge graph
            logic_node (GetSPONode): Current logical node

        Returns:
            List[str]: Retrieved text chunks
        """
        all_entities = kg_graph.get_all_entity()
        return self.ppr_chunk_retriever.invoke(
            queries=[logic_node.sub_query], start_entities=all_entities, top_k=10
        )

    def _generate_summary(
        self, logic_node: GetSPONode, chunks: List[str], kg_graph: KgGraph
    ):
        """Generate summary using LLM

        Args:
            logic_node (GetSPONode): Current logical node
            chunks (List[str]): Retrieved text chunks
            kg_graph (KgGraph): Knowledge graph data

        Returns:
            str: Generated summary text
        """
        relations = kg_graph.edge_map.get(logic_node.p.alias_name, [])
        return self.llm_client.invoke(
            {"question": logic_node.sub_query, "docs": chunks, "knowledge_graph": relations, "history": ""},
            init_prompt_with_fallback("sub_question_summary", KAG_PROJECT_CONF.biz_scene),
        )

    def _save_step_result(
        self,
        response: KAGRetrievedResponse,
        logic_node: GetSPONode,
        chunks: List[str],
        summary: str,
        kg_graph: KgGraph,
    ):
        """Save intermediate processing results

        Args:
            response (KAGRetrievedResponse): Aggregation container
            logic_node (GetSPONode): Current logical node
            chunks (List[str]): Retrieved text chunks
            summary (str): Generated summary
            kg_graph (KgGraph): Knowledge graph data
        """
        result = SubRetrievedData()
        result.sub_question = logic_node.sub_query
        result.summary = summary
        result.chunks = chunks
        result.spo = kg_graph.edge_map.get(logic_node.p.alias_name, [])
        response.sub_retrieved_set.append(result)

    def _store_results(self, task, response: KAGRetrievedResponse):
        """Store final results in task context

        Args:
            task: Task configuration object
            response (KAGRetrievedResponse): Processed results
        """
        task.update_memory("response", response)
        task.update_result(response)

    def schema(self) -> dict:
        """Function schema definition for OpenAI Function Calling

        Returns:
            dict: Schema definition in OpenAI Function format
        """
        return {
            "name": "kag_retriever_executor",
            "description": "Retrieve knowledge graph paths based on query and context to answer questions",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "User input question or query text",
                    }
                },
                "required": ["query"],
            },
        }
